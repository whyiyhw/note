**阶段一** 单机
企业刚发展的阶段，最简单，一个应用服务器配一个关系型数据库，每次读写数据库。
// php 8核心16G 100qps

**阶段二** 负载均衡/session共享
无论是使用 MySQL 还是 Oracle 还是别的关系型数据库，数据库通常不会先成为性能瓶颈，通常随着企业规模的扩大，一台应用服务器扛不住上游过来的流量且一台应用服务器会产生单点故障的问题。
因此加应用服务器并且在流量入口使用 Nginx 做一层负载均衡，保证把流量均匀打到应用服务器上。

**阶段三** 数据库主从复制/读写分离
随着企业规模的继续扩大，此时由于读写都在同一个数据库上，数据库性能出现一定的瓶颈。
此时简单地做一层读写分离，每次写主库，读备库，主备库之间通过 Binlog 同步数据，就能很大程度上解决这个阶段的数据库性能问题。

**阶段四** 分库分表
企业发展越来越好了，业务越来越大了，做了读写分离数据库压力还是越来越大，这时候怎么办呢？
一台数据库扛不住，那我们就分几台吧，做分库分表，对表做垂直拆分，对库做水平拆分。
以扩数据库为例，扩出两台数据库，以一定的单号（例如交易单号），以一定的规则（例如取模）。
交易单号对 2 取模为 0 的丢到数据库 1 去，交易单号对 2 取模为 1 的丢到数据库 2 去，通过这样的方式将写数据库的流量均分到两台数据库上。
一般分库分表会使用 Shard 的方式，通过一个中间件，便于连接管理、数据监控且客户端无需感知数据库 IP。

**关系型数据库的优点**

上面的方式，看似可以解决问题（实际上确实也能解决很多问题），正常对关系型数据库做一下读写分离+分库分表，支撑个 1W+ 的读写 QPS 还是问题不大的。

但是受限于关系型数据库本身，这套架构方案依然有着明显的不足，下面对利用关系型数据库方式做存储的方案的优点先进行一下分析，后一部分再分析一下缺点，对某个技术的优缺点的充分理解是技术选型的前提。

- ①易理解

因为行+列的二维表逻辑是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型更加容易被理解。

- ②操作方便

通用的 SQL 语言使得操作关系型数据库非常方便，支持 Join 等复杂查询。

- ③数据一致性

支持 ACID 特性，可以维护数据之间的一致性，这是使用数据库非常重要的一个理由之一。

- ④数据稳定

数据持久化到磁盘，没有丢失数据风险，支持海量数据存储。

- ⑤服务稳定

最常用的关系型数据库产品 MySQL、Oracle 服务器性能卓越，服务稳定，通常很少出现宕机异常。


**关系型数据库的缺点**

紧接着的，我们看一下关系型数据库的缺点，也是比较明显的。

- ①高并发下 IO 压力大

数据按行存储，即使只针对其中某一列进行运算，也会将整行数据从存储设备中读入内存，导致 IO 较高。

- ②为维护索引付出的代价大

为了提供丰富的查询能力，通常热点表都会有多个二级索引，一旦有了二级索引，数据的新增必然伴随着所有二级索引的新增。

数据的更新也必然伴随着所有二级索引的更新，这不可避免地降低了关系型数据库的读写能力，且索引越多读写能力越差。

有机会的话可以看一下自己公司的数据库，除了数据文件不可避免地占空间外，索引占的空间其实也并不少。

- ③为维护数据一致性付出的代价大

数据一致性是关系型数据库的核心，但是同样为了维护数据一致性的代价也是非常大的。

我们都知道 SQL 标准为事务定义了不同的隔离级别，从低到高依次是读未提交、读已提交、可重复读、串行化，事务隔离级别月底，可能出现的并发异常越多，但是通常而言能提供的并发能力越强。

那么为了保证事务一致性，数据库就需要提供并发控制与故障恢复两种技术，前者用于减少并发异常，后者可以在系统异常的时候保证事务与数据库状态不会被破坏。

对于并发控制，其核心思想就是加锁，无论是乐观锁还是悲观锁，只要提供的隔离级别越高，那么读写性能必然越差。

- ④水平扩展后带来的种种问题难处理

前文提过，随着企业规模扩大，一种方式是对数据库做分库，做了分库之后，数据迁移（1 个库的数据按照一定规则打到 2 个库中）、跨库 Join（订单数据里有用户数据，两条数据不在同一个库中）、分布式事务处理都是需要考虑的问题，尤其是分布式事务处理，业界当前都没有特别好的解决方案。

- ⑤表结构扩展不方便

由于数据库存储的是结构化数据，因此表结构 Schema 是固定的，扩展不方便，如果需要修改表结构，需要执行 DDL（data definition language）语句修改，修改期间会导致锁表，部分服务不可用。

- ⑥全文搜索功能弱

例如 like "%中国真伟大%"，只能搜索到"2019年中国真伟大，爱祖国"，无法搜索到"中国真是太伟大了"这样的文本，即不具备分词能力。

且 like 查询在"%中国真伟大"这样的搜索条件下，无法命中索引，将会导致查询效率大大降低。

写了这么多，我的理解核心还是前三点，它反映出的一个问题是
`关系型数据库在高并发下的能力是有瓶颈的`。
尤其是写入/更新频繁的情况下，出现瓶颈的结果就是数据库 CPU 高、SQL 执行慢、客户端报数据库连接池不够等错误，因此例如万人秒杀这种场景，我们绝对不可能通过数据库直接去扣减库存。